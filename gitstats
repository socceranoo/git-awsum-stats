#!/usr/bin/env python
# Copyright (c) 2007-2013 Heikki Hokkanen <hoxu@users.sf.net> & others (see doc/AUTHOR)
# GPLv2 / GPLv3
import datetime
import getopt
import glob
import os
import pickle
import platform
import re
import shutil
import subprocess
import sys
import time
import zlib
import json
import math

if sys.version_info < (2, 6):
       print >> sys.stderr, "Python 2.6 or higher is required for gitstats"
       sys.exit(1)

from multiprocessing import Pool

os.environ['LC_ALL'] = 'C'

GNUPLOT_COMMON = 'set terminal png transparent size 640,240\nset size 1.0,1.0\n'
ON_LINUX = (platform.system() == 'Linux')
WEEKDAYS = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')
MONTHS = ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')

exectime_internal = 0.0
exectime_external = 0.0
time_start = time.time()

# By default, gnuplot is searched from path, but can be overridden with the
# environment variable "GNUPLOT"
gnuplot_cmd = 'gnuplot'
if 'GNUPLOT' in os.environ:
	gnuplot_cmd = os.environ['GNUPLOT']

conf = {
	'max_domains': 10,
	'max_ext_length': 10,
	'style': 'gitstats.css',
	'max_authors': 20,
	'authors_top': 5,
	'commit_begin': '',
	'commit_end': 'HEAD',
	'linear_linestats': 1,
	'project_name': '',
	'merge_authors': {},
	'processes': 8,
}

def getpipeoutput(cmds, quiet = False):
	global exectime_external
	start = time.time()
	if not quiet and ON_LINUX and os.isatty(1):
		print '>> ' + ' | '.join(cmds),
		sys.stdout.flush()
	p0 = subprocess.Popen(cmds[0], stdout = subprocess.PIPE, shell = True)
	p = p0
	for x in cmds[1:]:
		p = subprocess.Popen(x, stdin = p0.stdout, stdout = subprocess.PIPE, shell = True)
		p0 = p
	output = p.communicate()[0]
	end = time.time()
	if not quiet:
		if ON_LINUX and os.isatty(1):
			print '\r',
		print '[%.5f] >> %s' % (end - start, ' | '.join(cmds))
	exectime_external += (end - start)
	return output.rstrip('\n')

def getcommitrange(defaultrange = 'HEAD', end_only = False):
	if len(conf['commit_end']) > 0:
		if end_only or len(conf['commit_begin']) == 0:
			return conf['commit_end']
		return '%s..%s' % (conf['commit_begin'], conf['commit_end'])
	return defaultrange

def getkeyssortedbyvalues(dict):
	return map(lambda el : el[1], sorted(map(lambda el : (el[1], el[0]), dict.items())))

# dict['author'] = { 'commits': 512 } - ...key(dict, 'commits')
def getkeyssortedbyvaluekey(d, key):
	return map(lambda el : el[1], sorted(map(lambda el : (d[el][key], el), d.keys())))

def getstatsummarycounts(line):
	numbers = re.findall('\d+', line)
	if   len(numbers) == 1:
		# neither insertions nor deletions: may probably only happen for "0 files changed"
		numbers.append(0);
		numbers.append(0);
	elif len(numbers) == 2 and line.find('(+)') != -1:
		numbers.append(0);    # only insertions were printed on line
	elif len(numbers) == 2 and line.find('(-)') != -1:
		numbers.insert(1, 0); # only deletions were printed on line
	return numbers

VERSION = 0
def getversion():
	global VERSION
	if VERSION == 0:
		gitstats_repo = os.path.dirname(os.path.abspath(__file__))
		VERSION = getpipeoutput(["git --git-dir=%s/.git --work-tree=%s rev-parse --short %s" %
			(gitstats_repo, gitstats_repo, getcommitrange('HEAD').split('\n')[0])])
	return VERSION

def getgitversion():
	return getpipeoutput(['git --version']).split('\n')[0]

def getgnuplotversion():
	return getpipeoutput(['%s --version' % gnuplot_cmd]).split('\n')[0]

def getnumoffilesfromrev(time_rev):
	"""
	Get number of files changed in commit
	"""
	time, rev = time_rev
	return (int(time), rev, int(getpipeoutput(['git ls-tree -r --name-only "%s"' % rev, 'wc -l']).split('\n')[0]))

def getnumoflinesinblob(ext_blob):
	"""
	Get number of lines in blob
	"""
	ext, blob_id = ext_blob
	return (ext, blob_id, int(getpipeoutput(['git cat-file blob %s' % blob_id, 'wc -l']).split()[0]))

class DataCollector:
	"""Manages data collection from a revision control repository."""
	def __init__(self):
		self.stamp_created = time.time()
		self.cache = {}
		self.total_authors = 0
		self.activity_by_hour_of_day = {} # hour -> commits
		self.activity_by_day_of_week = {} # day -> commits
		self.activity_by_month_of_year = {} # month [1-12] -> commits
		self.activity_by_hour_of_week = {} # weekday -> hour -> commits
		self.activity_by_hour_of_day_busiest = 0
		self.activity_by_hour_of_week_busiest = 0
		self.activity_by_year_week = {} # yy_wNN -> commits
		self.activity_by_year_week_peak = 0

		self.authors = {} # name -> {commits, first_commit_stamp, last_commit_stamp, last_active_day, active_days, lines_added, lines_removed}

		self.total_commits = 0
		self.total_files = 0
		self.authors_by_commits = 0

		# domains
		self.domains = {} # domain -> commits

		# author of the month
		self.author_of_month = {} # month -> author -> commits
		self.author_of_year = {} # year -> author -> commits
		self.commits_by_month = {} # month -> commits
		self.commits_by_year = {} # year -> commits
		self.lines_added_by_month = {} # month -> lines added
		self.lines_added_by_year = {} # year -> lines added
		self.lines_removed_by_month = {} # month -> lines removed
		self.lines_removed_by_year = {} # year -> lines removed
		self.first_commit_stamp = 0
		self.last_commit_stamp = 0
		self.last_active_day = None
		self.active_days = set()

		# lines
		self.total_lines = 0
		self.total_lines_added = 0
		self.total_lines_removed = 0

		# size
		self.total_size = 0

		# timezone
		self.commits_by_timezone = {} # timezone -> commits

		# tags
		self.tags = {}

		self.files_by_stamp = {} # stamp -> files

		# extensions
		self.extensions = {} # extension -> files, lines

		# line statistics
		self.changes_by_date = {} # stamp -> { files, ins, del }

	##
	# This should be the main function to extract data from the repository.
	def collect(self, dir):
		self.dir = dir
		if len(conf['project_name']) == 0:
			self.projectname = os.path.basename(os.path.abspath(dir))
		else:
			self.projectname = conf['project_name']
	
	##
	# Load cacheable data
	def loadCache(self, cachefile):
		if not os.path.exists(cachefile):
			return
		print 'Loading cache...'
		f = open(cachefile, 'rb')
		try:
			self.cache = pickle.loads(zlib.decompress(f.read()))
		except:
			# temporary hack to upgrade non-compressed caches
			f.seek(0)
			self.cache = pickle.load(f)
		f.close()
	
	##
	# Produce any additional statistics from the extracted data.
	def refine(self):
		pass

	##
	# : get a dictionary of author
	def getAuthorInfo(self, author):
		return None
	
	def getActivityByDayOfWeek(self):
		return {}

	def getActivityByHourOfDay(self):
		return {}

	# : get a dictionary of domains
	def getDomainInfo(self, domain):
		return None

	##
	# Get a list of authors
	def getAuthors(self):
		return []
	
	def getFirstCommitDate(self):
		return datetime.datetime.now()
	
	def getLastCommitDate(self):
		return datetime.datetime.now()
	
	def getStampCreated(self):
		return self.stamp_created
	
	def getTags(self):
		return []
	
	def getTotalAuthors(self):
		return -1
	
	def getTotalCommits(self):
		return -1
		
	def getTotalFiles(self):
		return -1
	
	def getTotalLOC(self):
		return -1
	
	##
	# Save cacheable data
	def saveCache(self, cachefile):
		print 'Saving cache...'
		tempfile = cachefile + '.tmp'
		f = open(tempfile, 'wb')
		#pickle.dump(self.cache, f)
		data = zlib.compress(pickle.dumps(self.cache))
		f.write(data)
		f.close()
		try:
			os.remove(cachefile)
		except OSError:
			pass
		os.rename(tempfile, cachefile)

class GitDataCollector(DataCollector):
	def collect(self, dir):
		DataCollector.collect(self, dir)

		self.total_authors += int(getpipeoutput(['git shortlog -s %s' % getcommitrange(), 'wc -l']))
		#self.total_lines = int(getoutput('git-ls-files -z |xargs -0 cat |wc -l'))

		# tags
		lines = getpipeoutput(['git show-ref --tags']).split('\n')
		for line in lines:
			if len(line) == 0:
				continue
			(hash, tag) = line.split(' ')

			tag = tag.replace('refs/tags/', '')
			output = getpipeoutput(['git log "%s" --pretty=format:"%%at %%aN" -n 1' % hash])
			if len(output) > 0:
				parts = output.split(' ')
				stamp = 0
				try:
					stamp = int(parts[0])
				except ValueError:
					stamp = 0
				self.tags[tag] = { 'stamp': stamp, 'hash' : hash, 'date' : datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), 'commits': 0, 'authors': {} }

		# collect info on tags, starting from latest
		tags_sorted_by_date_desc = map(lambda el : el[1], reversed(sorted(map(lambda el : (el[1]['date'], el[0]), self.tags.items()))))
		prev = None
		for tag in reversed(tags_sorted_by_date_desc):
			cmd = 'git shortlog -s "%s"' % tag
			if prev != None:
				cmd += ' "^%s"' % prev
			output = getpipeoutput([cmd])
			if len(output) == 0:
				continue
			prev = tag
			for line in output.split('\n'):
				parts = re.split('\s+', line, 2)
				commits = int(parts[1])
				author = parts[2]
				if author in conf['merge_authors']:
					author = conf['merge_authors'][author]
				self.tags[tag]['commits'] += commits
				self.tags[tag]['authors'][author] = commits

		# Collect revision statistics
		# Outputs "<stamp> <date> <time> <timezone> <author> '<' <mail> '>'"
		lines = getpipeoutput(['git rev-list --pretty=format:"%%at %%ai %%aN <%%aE>" %s' % getcommitrange('HEAD'), 'grep -v ^commit']).split('\n')
		for line in lines:
			parts = line.split(' ', 4)
			author = ''
			try:
				stamp = int(parts[0])
			except ValueError:
				stamp = 0
			timezone = parts[3]
			author, mail = parts[4].split('<', 1)
			author = author.rstrip()
			if author in conf['merge_authors']:
				author = conf['merge_authors'][author]
			mail = mail.rstrip('>')
			domain = '?'
			if mail.find('@') != -1:
				domain = mail.rsplit('@', 1)[1]
			date = datetime.datetime.fromtimestamp(float(stamp))

			# First and last commit stamp (may be in any order because of cherry-picking and patches)
			if stamp > self.last_commit_stamp:
				self.last_commit_stamp = stamp
			if self.first_commit_stamp == 0 or stamp < self.first_commit_stamp:
				self.first_commit_stamp = stamp

			# activity
			# hour
			hour = date.hour
			self.activity_by_hour_of_day[hour] = self.activity_by_hour_of_day.get(hour, 0) + 1
			# most active hour?
			if self.activity_by_hour_of_day[hour] > self.activity_by_hour_of_day_busiest:
				self.activity_by_hour_of_day_busiest = self.activity_by_hour_of_day[hour]

			# day of week
			day = date.weekday()
			self.activity_by_day_of_week[day] = self.activity_by_day_of_week.get(day, 0) + 1

			# domain stats
			if domain not in self.domains:
				self.domains[domain] = {}
			# commits
			self.domains[domain]['commits'] = self.domains[domain].get('commits', 0) + 1

			# hour of week
			if day not in self.activity_by_hour_of_week:
				self.activity_by_hour_of_week[day] = {}
			self.activity_by_hour_of_week[day][hour] = self.activity_by_hour_of_week[day].get(hour, 0) + 1
			# most active hour?
			if self.activity_by_hour_of_week[day][hour] > self.activity_by_hour_of_week_busiest:
				self.activity_by_hour_of_week_busiest = self.activity_by_hour_of_week[day][hour]

			# month of year
			month = date.month
			self.activity_by_month_of_year[month] = self.activity_by_month_of_year.get(month, 0) + 1

			# yearly/weekly activity
			yyw = date.strftime('%Y-%W')
			self.activity_by_year_week[yyw] = self.activity_by_year_week.get(yyw, 0) + 1
			if self.activity_by_year_week_peak < self.activity_by_year_week[yyw]:
				self.activity_by_year_week_peak = self.activity_by_year_week[yyw]

			# author stats
			if author not in self.authors:
				self.authors[author] = {}
			# commits, note again that commits may be in any date order because of cherry-picking and patches
			if 'last_commit_stamp' not in self.authors[author]:
				self.authors[author]['last_commit_stamp'] = stamp
			if stamp > self.authors[author]['last_commit_stamp']:
				self.authors[author]['last_commit_stamp'] = stamp
			if 'first_commit_stamp' not in self.authors[author]:
				self.authors[author]['first_commit_stamp'] = stamp
			if stamp < self.authors[author]['first_commit_stamp']:
				self.authors[author]['first_commit_stamp'] = stamp

			# author of the month/year
			yymm = date.strftime('%Y-%m')
			if yymm in self.author_of_month:
				self.author_of_month[yymm][author] = self.author_of_month[yymm].get(author, 0) + 1
			else:
				self.author_of_month[yymm] = {}
				self.author_of_month[yymm][author] = 1
			self.commits_by_month[yymm] = self.commits_by_month.get(yymm, 0) + 1

			yy = date.year
			if yy in self.author_of_year:
				self.author_of_year[yy][author] = self.author_of_year[yy].get(author, 0) + 1
			else:
				self.author_of_year[yy] = {}
				self.author_of_year[yy][author] = 1
			self.commits_by_year[yy] = self.commits_by_year.get(yy, 0) + 1

			# authors: active days
			yymmdd = date.strftime('%Y-%m-%d')
			if 'last_active_day' not in self.authors[author]:
				self.authors[author]['last_active_day'] = yymmdd
				self.authors[author]['active_days'] = set([yymmdd])
			elif yymmdd != self.authors[author]['last_active_day']:
				self.authors[author]['last_active_day'] = yymmdd
				self.authors[author]['active_days'].add(yymmdd)

			# project: active days
			if yymmdd != self.last_active_day:
				self.last_active_day = yymmdd
				self.active_days.add(yymmdd)

			# timezone
			self.commits_by_timezone[timezone] = self.commits_by_timezone.get(timezone, 0) + 1

		# outputs "<stamp> <files>" for each revision
		revlines = getpipeoutput(['git rev-list --pretty=format:"%%at %%T" %s' % getcommitrange('HEAD'), 'grep -v ^commit']).strip().split('\n')
		lines = []
		revs_to_read = []
		time_rev_count = []
		#Look up rev in cache and take info from cache if found
		#If not append rev to list of rev to read from repo
		for revline in revlines:
			time, rev = revline.split(' ')
			#if cache empty then add time and rev to list of new rev's
			#otherwise try to read needed info from cache
			if 'files_in_tree' not in self.cache.keys():
				revs_to_read.append((time,rev))
				continue
			if rev in self.cache['files_in_tree'].keys():
				lines.append('%d %d' % (int(time), self.cache['files_in_tree'][rev]))
			else:
				revs_to_read.append((time,rev))

		#Read revisions from repo
		time_rev_count = Pool(processes=conf['processes']).map(getnumoffilesfromrev, revs_to_read)

		#Update cache with new revisions and append then to general list
		for (time, rev, count) in time_rev_count:
			if 'files_in_tree' not in self.cache:
				self.cache['files_in_tree'] = {}
			self.cache['files_in_tree'][rev] = count
			lines.append('%d %d' % (int(time), count))

		self.total_commits += len(lines)
		for line in lines:
			parts = line.split(' ')
			if len(parts) != 2:
				continue
			(stamp, files) = parts[0:2]
			try:
				self.files_by_stamp[int(stamp)] = int(files)
			except ValueError:
				print 'Warning: failed to parse line "%s"' % line

		# extensions and size of files
		lines = getpipeoutput(['git ls-tree -r -l -z %s' % getcommitrange('HEAD', end_only = True)]).split('\000')
		blobs_to_read = []
		for line in lines:
			if len(line) == 0:
				continue
			parts = re.split('\s+', line, 5)
			if parts[0] == '160000' and parts[3] == '-':
				# skip submodules
				continue
			blob_id = parts[2]
			size = int(parts[3])
			fullpath = parts[4]

			self.total_size += size
			self.total_files += 1

			filename = fullpath.split('/')[-1] # strip directories
			if filename.find('.') == -1 or filename.rfind('.') == 0:
				ext = ''
			else:
				ext = filename[(filename.rfind('.') + 1):]
			if len(ext) > conf['max_ext_length']:
				ext = ''
			if ext not in self.extensions:
				self.extensions[ext] = {'files': 0, 'lines': 0}
			self.extensions[ext]['files'] += 1
			#if cache empty then add ext and blob id to list of new blob's
			#otherwise try to read needed info from cache
			if 'lines_in_blob' not in self.cache.keys():
				blobs_to_read.append((ext,blob_id))
				continue
			if blob_id in self.cache['lines_in_blob'].keys():
				self.extensions[ext]['lines'] += self.cache['lines_in_blob'][blob_id]
			else:
				blobs_to_read.append((ext,blob_id))

		#Get info abount line count for new blob's that wasn't found in cache
		ext_blob_linecount = Pool(processes=24).map(getnumoflinesinblob, blobs_to_read)

		#Update cache and write down info about number of number of lines
		for (ext, blob_id, linecount) in ext_blob_linecount:
			if 'lines_in_blob' not in self.cache:
				self.cache['lines_in_blob'] = {}
			self.cache['lines_in_blob'][blob_id] = linecount
			self.extensions[ext]['lines'] += self.cache['lines_in_blob'][blob_id]

		# line statistics
		# outputs:
		#  N files changed, N insertions (+), N deletions(-)
		# <stamp> <author>
		self.changes_by_date = {} # stamp -> { files, ins, del }
		# computation of lines of code by date is better done
		# on a linear history.
		extra = ''
		if conf['linear_linestats']:
			extra = '--first-parent -m'
		lines = getpipeoutput(['git log --shortstat %s --pretty=format:"%%at %%aN" %s' % (extra, getcommitrange('HEAD'))]).split('\n')
		lines.reverse()
		files = 0; inserted = 0; deleted = 0; total_lines = 0
		author = None
		for line in lines:
			if len(line) == 0:
				continue

			# <stamp> <author>
			if re.search('files? changed', line) == None:
				pos = line.find(' ')
				if pos != -1:
					try:
						(stamp, author) = (int(line[:pos]), line[pos+1:])
						if author in conf['merge_authors']:
							author = conf['merge_authors'][author]
						self.changes_by_date[stamp] = { 'files': files, 'ins': inserted, 'del': deleted, 'lines': total_lines }

						date = datetime.datetime.fromtimestamp(stamp)
						yymm = date.strftime('%Y-%m')
						self.lines_added_by_month[yymm] = self.lines_added_by_month.get(yymm, 0) + inserted
						self.lines_removed_by_month[yymm] = self.lines_removed_by_month.get(yymm, 0) + deleted

						yy = date.year
						self.lines_added_by_year[yy] = self.lines_added_by_year.get(yy,0) + inserted
						self.lines_removed_by_year[yy] = self.lines_removed_by_year.get(yy, 0) + deleted

						files, inserted, deleted = 0, 0, 0
					except ValueError:
						print 'Warning: unexpected line "%s"' % line
				else:
					print 'Warning: unexpected line "%s"' % line
			else:
				numbers = getstatsummarycounts(line)

				if len(numbers) == 3:
					(files, inserted, deleted) = map(lambda el : int(el), numbers)
					total_lines += inserted
					total_lines -= deleted
					self.total_lines_added += inserted
					self.total_lines_removed += deleted

				else:
					print 'Warning: failed to handle line "%s"' % line
					(files, inserted, deleted) = (0, 0, 0)
				#self.changes_by_date[stamp] = { 'files': files, 'ins': inserted, 'del': deleted }
		self.total_lines += total_lines

		# Per-author statistics

		# defined for stamp, author only if author commited at this timestamp.
		self.changes_by_date_by_author = {} # stamp -> author -> lines_added

		# Similar to the above, but never use --first-parent
		# (we need to walk through every commit to know who
		# committed what, not just through mainline)
		lines = getpipeoutput(['git log --shortstat --date-order --pretty=format:"%%at %%aN" %s' % (getcommitrange('HEAD'))]).split('\n')
		lines.reverse()
		files = 0; inserted = 0; deleted = 0
		author = None
		stamp = 0
		for line in lines:
			if len(line) == 0:
				continue

			# <stamp> <author>
			if re.search('files? changed', line) == None:
				pos = line.find(' ')
				if pos != -1:
					try:
						oldstamp = stamp
						(stamp, author) = (int(line[:pos]), line[pos+1:])
						if author in conf['merge_authors']:
							author = conf['merge_authors'][author]
						if oldstamp > stamp:
							# clock skew, keep old timestamp to avoid having ugly graph
							stamp = oldstamp
						if author not in self.authors:
							self.authors[author] = { 'lines_added' : 0, 'lines_removed' : 0, 'commits' : 0}
						self.authors[author]['commits'] = self.authors[author].get('commits', 0) + 1
						self.authors[author]['lines_added'] = self.authors[author].get('lines_added', 0) + inserted
						self.authors[author]['lines_removed'] = self.authors[author].get('lines_removed', 0) + deleted
						if stamp not in self.changes_by_date_by_author:
							self.changes_by_date_by_author[stamp] = {}
						if author not in self.changes_by_date_by_author[stamp]:
							self.changes_by_date_by_author[stamp][author] = {}
						self.changes_by_date_by_author[stamp][author]['lines_added'] = self.authors[author]['lines_added']
						self.changes_by_date_by_author[stamp][author]['commits'] = self.authors[author]['commits']
						files, inserted, deleted = 0, 0, 0
					except ValueError:
						print 'Warning: unexpected line "%s"' % line
				else:
					print 'Warning: unexpected line "%s"' % line
			else:
				numbers = getstatsummarycounts(line);

				if len(numbers) == 3:
					(files, inserted, deleted) = map(lambda el : int(el), numbers)
				else:
					print 'Warning: failed to handle line "%s"' % line
					(files, inserted, deleted) = (0, 0, 0)
	
	def refine(self):
		# authors
		# name -> {place_by_commits, commits_frac, date_first, date_last, timedelta}
		self.authors_by_commits = getkeyssortedbyvaluekey(self.authors, 'commits')
		self.authors_by_commits.reverse() # most first
		for i, name in enumerate(self.authors_by_commits):
			self.authors[name]['place_by_commits'] = i + 1

		for name in self.authors.keys():
			a = self.authors[name]
			a['commits_frac'] = (100 * float(a['commits'])) / self.getTotalCommits()
			date_first = datetime.datetime.fromtimestamp(a['first_commit_stamp'])
			date_last = datetime.datetime.fromtimestamp(a['last_commit_stamp'])
			delta = date_last - date_first
			a['date_first'] = date_first.strftime('%Y-%m-%d')
			a['date_last'] = date_last.strftime('%Y-%m-%d')
			a['timedelta'] = delta
			if 'lines_added' not in a: a['lines_added'] = 0
			if 'lines_removed' not in a: a['lines_removed'] = 0
	
	def getActiveDays(self):
		return self.active_days

	def getActivityByDayOfWeek(self):
		return self.activity_by_day_of_week

	def getActivityByHourOfDay(self):
		return self.activity_by_hour_of_day

	def getAuthorInfo(self, author):
		return self.authors[author]
	
	def getAuthors(self, limit = None):
		res = getkeyssortedbyvaluekey(self.authors, 'commits')
		res.reverse()
		return res[:limit]
	
	def getCommitDeltaDays(self):
		return (self.last_commit_stamp / 86400 - self.first_commit_stamp / 86400) + 1

	def getDomainInfo(self, domain):
		return self.domains[domain]

	def getDomains(self):
		return self.domains.keys()
	
	def getFirstCommitDate(self):
		return datetime.datetime.fromtimestamp(self.first_commit_stamp)
	
	def getLastCommitDate(self):
		return datetime.datetime.fromtimestamp(self.last_commit_stamp)
	
	def getTags(self):
		lines = getpipeoutput(['git show-ref --tags', 'cut -d/ -f3'])
		return lines.split('\n')
	
	def getTagDate(self, tag):
		return self.revToDate('tags/' + tag)
	
	def getTotalAuthors(self):
		return self.total_authors
	
	def getTotalCommits(self):
		return self.total_commits

	def getTotalFiles(self):
		return self.total_files
	
	def getTotalLOC(self):
		return self.total_lines

	def getTotalSize(self):
		return self.total_size
	
	def revToDate(self, rev):
		stamp = int(getpipeoutput(['git log --pretty=format:%%at "%s" -n 1' % rev]))
		return datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d')

class ReportCreator:
	"""Creates the actual report based on given data."""
	def __init__(self):
		pass
	
	def create(self, data, path):
		self.data = data
		self.path = path

def html_linkify(text):
	return text.lower().replace(' ', '_')

def html_header(level, text):
	#name = html_linkify(text)
	return '\t\t<h%d>%s</h%d>\n' % (level, text, level)

class HTMLReportCreator(ReportCreator):
	def create(self, data, path):
		ReportCreator.create(self, data, path)
		self.title = data.projectname

		self.copystaticfiles(path)
		self.indexhtml(data, path)
		self.activityhtml(data, path)
		self.authorhtml(data, path)
		self.filehtml(data, path)
		self.linehtml(data, path)
		self.taghtml(data, path)

	def copystaticfiles(self, path) :
		# copy static files. 
		src="assets/css"
		src_files = os.listdir(src)
		for file_name in src_files:
			full_file_name = os.path.join(src, file_name)
			if (os.path.isfile(full_file_name)):
				shutil.copy(full_file_name, path + '/assets/css/' + file_name)

		src="assets/js"
		src_files = os.listdir(src)
		for file_name in src_files:
			full_file_name = os.path.join(src, file_name)
			if (os.path.isfile(full_file_name)):
				shutil.copy(full_file_name, path + '/assets/js/' + file_name)

		src="assets/images"
		src_files = os.listdir(src)
		for file_name in src_files:
			full_file_name = os.path.join(src, file_name)
			if (os.path.isfile(full_file_name)):
				shutil.copy(full_file_name, path + '/assets/images/' + file_name)

	def indexhtml(self, data, path):
		f = open(path + "/index.html", 'w')
		format = '%b %d %Y %H:%M:%S'
		self.printHeader(f, 'Index', data.projectname)
		f.write("""
		<div class=row>
			<div class='span2 text-center'>
			</div>
			<div class='span8 text-center ipad-bg'>
		""")
		f.write("""
			</div>
		</div>
		""")

		f.write('\t\t<dl>\n')
		f.write('\t\t\t<dt>Project name</dt><dd>%s</dd>\n' % (data.projectname))
		f.write('\t\t\t<dt>Generated</dt><dd>%s (in %d seconds)</dd>\n' % (datetime.datetime.now().strftime(format), time.time() - data.getStampCreated()))
		f.write('\t\t\t<dt>Generator</dt><dd><a href="http://gitstats.sourceforge.net/">GitStats</a> (version %s), %s, %s</dd>\n' % (getversion(), getgitversion(), getgnuplotversion()))
		f.write('\t\t\t<dt>Report Period</dt><dd>%s to %s</dd>\n' % (data.getFirstCommitDate().strftime(format), data.getLastCommitDate().strftime(format)))
		f.write('\t\t\t<dt>Age</dt><dd>%d days, %d active days (%3.2f%%)</dd>\n' % (data.getCommitDeltaDays(), len(data.getActiveDays()), (100.0 * len(data.getActiveDays()) / data.getCommitDeltaDays())))
		f.write('\t\t\t<dt>Total Files</dt><dd>%s</dd>\n' % data.getTotalFiles())
		f.write('\t\t\t<dt>Total Lines of Code</dt><dd>%s (%d added, %d removed)</dd>\n' % (data.getTotalLOC(), data.total_lines_added, data.total_lines_removed))
		f.write('\t\t\t<dt>Total Commits</dt><dd>%s (average %.1f commits per active day, %.1f per all days)</dd>\n' % (data.getTotalCommits(), float(data.getTotalCommits()) / len(data.getActiveDays()), float(data.getTotalCommits()) / data.getCommitDeltaDays()))
		f.write('\t\t\t<dt>Authors</dt><dd>%s (average %.1f commits per author)</dd>\n' % (data.getTotalAuthors(), (1.0 * data.getTotalCommits()) / data.getTotalAuthors()))
		f.write('\t\t</dl>\n')

		self.printFooter(f)
		f.close()

	def activityhtml(self, data, path):
		###
		# Activity
		activities_array = {}
		f = open(path + '/activity.html', 'w')
		self.printHeader(f, 'Activity')

		# Weekly activity
		WEEKS = 32
		divid = 'weekly-activity'
		weekly_activity = {'divid':divid, 'title':'Weekly Activity (Last '+str(WEEKS)+' weeks)', 'type':'bar', 'horizontal':0, 'xaxis':{'label':'week', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'none', 'value':[]}, 'upperlimit':WEEKS, 'numberformat':'%d'}
		#f.write(html_header(2, 'Weekly activity'))
		self.createDiv(f, divid, "div")
		# generate weeks to show (previous N weeks from now)
		now = datetime.datetime.now()
		deltaweek = datetime.timedelta(7)
		weeks = []
		stampcur = now
		for i in range(0, WEEKS):
			weeks.insert(0, stampcur.strftime('%Y-%W'))
			stampcur -= deltaweek
		# top row: commits & bar
		for i in range(0, WEEKS):
			commits = 0
			#percentage = 0
			if weeks[i] in data.activity_by_year_week:
				commits = data.activity_by_year_week[weeks[i]]
				#percentage = float(data.activity_by_year_week[weeks[i]]) / data.activity_by_year_week_peak
			#height = max(1, int(200 * percentage))
			weekly_activity['yaxis']['value'].append(commits)
			weekly_activity['xaxis']['value'].append((WEEKS - i))
			#f.write('<td style="text-align: center; vertical-align: bottom">%d<div style="display: block; background-color: red; width: 20px; height: %dpx"></div></td>' % (commits, height))

		activities_array['weekly_activity'] = weekly_activity;

		# Hour of Day

		divid = 'hour-of-day'
		hour_of_day_obj = {'divid':divid, 'title':'Hour of Day', 'type':'bar', 'horizontal':0, 'xaxis':{'label':'hour', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'percentage', 'value':[]}, 'upperlimit':24, 'numberformat':'%d'}
		#f.write(html_header(2, 'Hour of Day'))
		self.createDiv(f, divid, "div")
		hour_of_day = data.getActivityByHourOfDay()
		fp = open(path + '/hour_of_day.dat', 'w')
		totalcommits = data.getTotalCommits()
		for i in range(0, 24):
			if i in hour_of_day:
				#r = 127 + int((float(hour_of_day[i]) / data.activity_by_hour_of_day_busiest) * 128)
				#f.write('<td style="background-color: rgb(%d, 0, 0)">%d</td>' % (r, hour_of_day[i]))
				hour_of_day_obj['yaxis']['value'].append(hour_of_day[i])
				hour_of_day_obj['xaxis']['value'].append(i+1)
				hour_of_day_obj['y2axis']['value'].append(((100.0 * hour_of_day[i]) / totalcommits))
				fp.write('%d %d\n' % (i + 1, hour_of_day[i]))
			else:
				fp.write('%d 0\n' % (i + 1))
		fp.close()
		activities_array['hour_of_day'] = hour_of_day_obj;

		# Day of Week
		divid = 'day-of-week';
		day_of_week_obj = {'divid':divid, 'title':'Day of Week', 'type':'pie', 'horizontal':0, 'data':{'label':'commits', 'value':[[]]}, 'xaxis':{'label':'day', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'percentage', 'value':[]}, 'upperlimit':7, 'numberformat':'%d'}
		#f.write(html_header(2, 'Day of Week'))
		self.createDiv(f, divid, "div")
		day_of_week = data.getActivityByDayOfWeek()
		fp = open(path + '/day_of_week.dat', 'w')
		for d in range(0, 7):
			commits = 0
			if d in day_of_week:
				commits = day_of_week[d]
			fp.write('%d %s %d\n' % (d + 1, WEEKDAYS[d], commits))
			day_of_week_obj['data']['value'][0].append([WEEKDAYS[d], commits])
			day_of_week_obj['yaxis']['value'].append(commits)
			day_of_week_obj['xaxis']['value'].append(WEEKDAYS[d])
			if d in day_of_week:
				day_of_week_obj['y2axis']['value'].append(((100.0 * day_of_week[d]) / totalcommits))
			else:
				day_of_week_obj['y2axis']['value'].append(0.00)
		fp.close()
		activities_array['day_of_week'] = day_of_week_obj;
		f.write("<a href='javascript:void(0);' class='btn btn-primary' id=change-colors>Change Colors</a>")

		divid = 'hour-of-week';
		# Hour of Week
		f.write('\t\t<h2 class="text-center heat-table-heading">Hour of Week</h2>')
		f.write('<table class="table plot heat-table">')
		f.write('<tr><th>Day</th>')
		for hour in range(0, 24):
			f.write('<th>%d</th>' % (hour))
		f.write('</tr>')
		for weekday in range(0, 7):
			f.write('<tr><th>%s</th>' % (WEEKDAYS[weekday]))
			for hour in range(0, 24):
				try:
					commits = data.activity_by_hour_of_week[weekday][hour]
				except KeyError:
					commits = 0
				if commits != 0:
					f.write('<td class=data ')
					r = 192 - int((float(commits) / data.activity_by_hour_of_week_busiest) * 192)
					f.write(' style="background-color: rgb(0, %d, 204)"' % r)
					f.write('>%d</td>' % commits)
				else:
					f.write('<td style="background-color:#eee">-</td>')
			f.write('</tr>')
		f.write('</table>')

		# Month of Year
		divid = 'month-of-year';
		month_of_year_obj = {'divid':divid, 'title':'Month of Year', 'type':'bar', 'horizontal':0, 'data':{'label':'commits', 'value':[[]]}, 'xaxis':{'label':'month', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'percentage', 'value':[]}, 'upperlimit':12, 'numberformat':'%d'}
		#f.write(html_header(2, 'Month of Year'))
		self.createDiv(f, divid, "div")
		fp = open (path + '/month_of_year.dat', 'w')
		for mm in range(1, 13):
			commits = 0
			if mm in data.activity_by_month_of_year:
				commits = data.activity_by_month_of_year[mm]
			index = 0 if(mm > 6) else 0;
			month_of_year_obj['data']['value'][index-1].append([MONTHS[mm-1], commits])
			month_of_year_obj['xaxis']['value'].append(MONTHS[mm-1])
			month_of_year_obj['yaxis']['value'].append(commits)
			month_of_year_obj['y2axis']['value'].append(((100.0 * commits) / data.getTotalCommits()))
			fp.write('%d %d\n' % (mm, commits))
		fp.close()
		activities_array['month_of_year'] = month_of_year_obj;

		# Commits by year/month
		f.write('\t\t<h2 class="text-center heat-table-heading">Year/Month</h2>')
		f.write('<table class="table plot heat-table">')
		f.write('<tr><th>Year</th>')
		for month in range(1, 13):
			f.write('<th>%s</th>' % (MONTHS[month-1]))
		f.write('</tr>')
		yy_range = sorted(data.commits_by_year.keys())
		max_value = sorted(data.commits_by_month.values())[-1]
		for yy in range(yy_range[0], yy_range[-1]+1):
			f.write('<tr><th>%d</th>' % (yy))
			for mm in range(1, 13):
				mm_str = "0"+str(mm) if(mm < 10) else str(mm)
				yymm = str(yy)+"-"+mm_str
				commits = data.commits_by_month.get(yymm,0)
				if commits != 0:
					f.write('<td class=data ')
					r = 160 - int((float(commits) / max_value) * 160)
					f.write(' style="background-color: rgb(204, %d, 0)"' % r)
					f.write('>%d</td>' % commits)
				else:
					f.write('<td style="background-color:#eee">-</td>')
				#data.lines_added_by_month.get(yymm,0)
				#data.lines_removed_by_month.get(yymm,0)
			f.write('</tr>')
		f.write('</table>')
			
		fg = open(path + '/commits_by_year_month.dat', 'w')
		for yymm in sorted(data.commits_by_month.keys()):
			fg.write('%s %s\n' % (yymm, data.commits_by_month[yymm]))
		fg.close()

		# Commits by year
		divid = 'year-commits';
		year_obj = {'divid':divid, 'title':'Yearly Activity', 'type':'bar', 'horizontal':0, 'xaxis':{'label':'year', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'percentage', 'value':[]}, 'y3axis':{'label':'lines-added', 'value':[]}, 'y4axis':{'label':'lines-removed', 'value':[]}, 'upperlimit':10, 'numberformat':'%d'}
		#f.write(html_header(2, 'Commits by Year'))
		self.createDiv(f, divid, "div")
		for yy in reversed(sorted(data.commits_by_year.keys())):
			year_obj['xaxis']['value'].append(yy)
			year_obj['yaxis']['value'].append(data.commits_by_year.get(yy,0))
			year_obj['y2axis']['value'].append(((100.0 * data.commits_by_year.get(yy,0)) / data.getTotalCommits()))
			year_obj['y3axis']['value'].append(data.lines_added_by_year.get(yy,0))
			year_obj['y4axis']['value'].append(data.lines_removed_by_year.get(yy,0))
		fg = open(path + '/commits_by_year.dat', 'w')
		for yy in sorted(data.commits_by_year.keys()):
			fg.write('%d %d\n' % (yy, data.commits_by_year[yy]))
		fg.close()
		activities_array['year'] = year_obj;

		# Commits by timezone
		divid = 'timezone-commits';
		timezone_obj = {'divid':divid, 'title':'Commits by Timezone', 'type':'bar', 'horizontal':0, 'xaxis':{'label':'timezone', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'upperlimit':24, 'numberformat':'%d'}
		#f.write(html_header(2, 'Commits by Timezone'))
		self.createDiv(f, divid, "div")
		max_commits_on_tz = max(data.commits_by_timezone.values())
		for i in sorted(data.commits_by_timezone.keys(), key = lambda n : int(n)):
			commits = data.commits_by_timezone[i]
			timezone_obj['xaxis']['value'].append(i)
			timezone_obj['yaxis']['value'].append(commits)
			#r = 127 + int((float(commits) / max_commits_on_tz) * 128)
			#f.write('<tr><th>%s</th><td style="background-color: rgb(%d, 0, 0)">%d</td></tr>' % (i, r, commits))
		activities_array['timezone'] = timezone_obj;

		# Domains
		divid = 'domain-commits';
		domain_obj = {'divid':divid, 'title':'Commits by Domain', 'type':'bar', 'horizontal':0, 'xaxis':{'label':'domain', 'value':[]}, 'yaxis':{'label':'commits', 'value':[]}, 'y2axis':{'label':'percentage', 'value':[]}, 'upperlimit':10, 'numberformat':'%d'}
		#f.write(html_header(2, 'Commits by Domains'))
		self.createDiv(f, divid, "div")
		domains_by_commits = getkeyssortedbyvaluekey(data.domains, 'commits')
		domains_by_commits.reverse() # most first
		fp = open(path + '/domains.dat', 'w')
		n = 0
		for domain in domains_by_commits:
			#if n == conf['max_domains']:
			#	break
			commits = 0
			n += 1
			info = data.getDomainInfo(domain)
			commits = info['commits']
			domain_obj['xaxis']['value'].append(domain)
			domain_obj['yaxis']['value'].append(commits)
			domain_obj['y2axis']['value'].append((100.0 * commits / data.getTotalCommits()))
			fp.write('%s %d %d\n' % (domain, n , info['commits']))
		fp.close()
		activities_array['domain'] = domain_obj;
		self.printDataDiv(f, 'activity', activities_array)
		self.printFooter(f)
		f.close()

	def authorhtml(self, data, path):
		###
		# Authors
		author_array = {}
		f = open(path + '/authors.html', 'w')
		self.printHeader(f, 'Authors')

		# Authors :: List of authors
		f.write(html_header(2, 'List of Authors'))
		author_list_obj = {'divid':'author-list', 'title':'List of authors', 'type':'table', 'horizontal':0, 'column_headers':[], 'rows':[], "sort_index":1, "sort_order":"desc", "show_count":10}
		self.createTable(f, author_list_obj['divid'], 'table');

		for column in ("Author", "Commits", "%", "lines-added", "lines-removed", "First commit", "Last commit", "Age", "Active days", "Rank") :
			author_list_obj['column_headers'].append({'sTitle':column, 'sClass':'center'})

		for author in data.getAuthors():
			info = data.getAuthorInfo(author)
			author = author.replace("'", "");
			author_list_obj['rows'].append([author, info['commits'], math.ceil(info['commits_frac'] * 100) / 100, info['lines_added'], info['lines_removed'], info['date_first'], info['date_last'], str(info['timedelta']), len(info['active_days']), info['place_by_commits']])

		author_array['author_list']=author_list_obj;

		f.write(html_header(2, 'Cumulated Added Lines of Code per Author'))

		f.write(html_header(2, 'Commits per Author'))

		fgl = open(path + '/lines_of_code_by_author.dat', 'w')
		fgc = open(path + '/commits_by_author.dat', 'w')

		lines_by_authors = {} # cumulated added lines by
		# author. to save memory,
		# changes_by_date_by_author[stamp][author] is defined
		# only at points where author commits.
		# lines_by_authors allows us to generate all the
		# points in the .dat file.

		# Don't rely on getAuthors to give the same order each
		# time. Be robust and keep the list in a variable.
		commits_by_authors = {} # cumulated added lines by

		self.authors_to_plot = data.getAuthors(conf['max_authors'])
		for author in self.authors_to_plot:
			lines_by_authors[author] = 0
			commits_by_authors[author] = 0
		for stamp in sorted(data.changes_by_date_by_author.keys()):
			fgl.write('%d' % stamp)
			fgc.write('%d' % stamp)
			for author in self.authors_to_plot:
				if author in data.changes_by_date_by_author[stamp].keys():
					lines_by_authors[author] = data.changes_by_date_by_author[stamp][author]['lines_added']
					commits_by_authors[author] = data.changes_by_date_by_author[stamp][author]['commits']
				fgl.write(' %d' % lines_by_authors[author])
				fgc.write(' %d' % commits_by_authors[author])
			fgl.write('\n')
			fgc.write('\n')
		fgl.close()
		fgc.close()
		#author_array['lines_by_authors']= lines_by_authors;
		#author_array['commits_by_authors']=commits_by_authors;

		# Authors :: Author of Month
		f.write(html_header(2, 'Author of Month'))
		author_of_month_obj = {'divid':'author-of-month', 'title':'Author of Month', 'type':'table', 'horizontal':0, 'column_headers':[], 'rows':[], "sort_index":0, "sort_order":"desc", "show_count":25}
		self.createTable(f, author_of_month_obj['divid'], 'table');

		for column in ("Month", "Name of the Author", "Commits", "%", "Total commits", "Top 5 authors", "# Authors") :
			author_of_month_obj['column_headers'].append({'sTitle':column, 'sClass':'center'})
		for yymm in reversed(sorted(data.author_of_month.keys())):
			authordict = data.author_of_month[yymm]
			authors = getkeyssortedbyvalues(authordict)
			authors.reverse()
			commits = data.author_of_month[yymm][authors[0]]
			next = ', '.join(authors[1:conf['authors_top']+1])
			next = next.replace("'", "");
			author = authors[0].replace("'", "");
			author_of_month_obj['rows'].append([yymm, author, commits, self.calculatePercentage(commits, data.commits_by_month[yymm]), data.commits_by_month[yymm], next, len(authors)])
		author_array['author_of_month'] = author_of_month_obj

		# Authors :: Author of Year
		f.write(html_header(2, 'Author of Year'))
		author_of_year_obj = {'divid':'author-of-year', 'title':'Author of Year', 'type':'table', 'horizontal':0, 'column_headers':[], 'rows':[], "sort_index":0, "sort_order":"desc", "show_count":10}
		self.createTable(f, author_of_year_obj['divid'], 'table');

		for column in ("Year", "Author", "Commits", "%", "Total commits", "Next top 5", "Number of Authors") :
			author_of_year_obj['column_headers'].append({'sTitle':column, 'sClass':'center'})
		for yy in reversed(sorted(data.author_of_year.keys())):
			authordict = data.author_of_year[yy]
			authors = getkeyssortedbyvalues(authordict)
			authors.reverse()
			commits = data.author_of_year[yy][authors[0]]
			next = ', '.join(authors[1:conf['authors_top']+1])
			next = next.replace("'", "");
			author = authors[0].replace("'", "");
			author_of_year_obj['rows'].append([yy, author, commits, self.calculatePercentage(commits, data.commits_by_year[yy]), data.commits_by_year[yy], next, len(authors)])
		author_array['author_of_year'] = author_of_year_obj
		self.printDataDiv(f, 'author', author_array)
		self.printFooter(f)
		f.close()
	def calculatePercentage (self, num, den):
		try:
			percentage = math.ceil((100.0 * num / den) * 100) /100
		except ZeroDivisionError:
			percentage = 0.00
		return percentage

	def linehtml(self, data, path):
		###
		# Lines
		f = open(path + '/lines.html', 'w')
		self.printHeader(f, 'Lines')

		f.write('<dl>\n')
		f.write('<dt>Total lines</dt><dd>%d</dd>' % data.getTotalLOC())
		f.write('</dl>\n')

		lines_array = {"total_lines":data.getTotalLOC()}

		line_count_obj = {'title':'Line Count by Date', 'type':'line', 'horizontal':0, 'line1':[]}
		f.write(html_header(2, 'Lines of Code'))

		fg = open(path + '/lines_of_code.dat', 'w')
		for stamp in sorted(data.changes_by_date.keys()):
			line_count_obj['line1'].append([datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), data.changes_by_date[stamp]['lines']])
			fg.write('%s %d\n' % (datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), data.changes_by_date[stamp]['lines']))
		fg.close()
		lines_array['lines_count'] = line_count_obj
		self.printDataDiv(f, 'lines', lines_array)
		self.printFooter(f)
		f.close()

	def taghtml(self, data, path):
		###
		# tags.html
		tags_array = {}
		f = open(path + '/tags.html', 'w')
		self.printHeader(f, 'Tags')
		#self.createTable(f, tags_obj['divid'], 'table');
		tags_array['total_tags'] = len(data.tags)
		try:
			tags_array['average_commit_per_tag'] = 0
			tags_array['average_commit_per_tag'] = (1.0 * data.getTotalCommits() / len(data.tags))
		except ZeroDivisionError:
			pass

		f.write('<dl>')
		f.write('<dt>Total tags</dt><dd>%d</dd>' % len(data.tags))
		if len(data.tags) > 0:
			f.write('<dt>Average commits per tag</dt><dd>%.2f</dd>' % (1.0 * data.getTotalCommits() / len(data.tags)))
		f.write('</dl>')

		tags_obj = {'divid':'tags-table', 'title':'Tags', 'type':'table-dom', 'horizontal':0, 'column_headers':[None, None, None, None], "sort_index":1, "sort_order":"desc", "show_count":10}
		f.write('<table id=tags-table cellpadding=0 cellspacing=0 class="table table-bordered display">')
		f.write('<thead><tr><th>Name</th><th>Date</th><th>Commits</th><th>Authors</th></tr></thead><tbody>')
		# sort the tags by date desc
		tags_sorted_by_date_desc = map(lambda el : el[1], reversed(sorted(map(lambda el : (el[1]['date'], el[0]), data.tags.items()))))
		for tag in tags_sorted_by_date_desc:
			authorinfo = []
			self.authors_by_commits = getkeyssortedbyvalues(data.tags[tag]['authors'])
			for i in reversed(self.authors_by_commits):
				authorinfo.append('%s (%d)' % (i, data.tags[tag]['authors'][i]))
			f.write('<tr><td>%s</td><td>%s</td><td>%d</td><td>%s</td></tr>' % (tag, data.tags[tag]['date'], data.tags[tag]['commits'], ', '.join(authorinfo)))
		f.write('</tbody></table>')

		tags_array['tags_obj'] = tags_obj
		self.printDataDiv(f, 'tags', tags_array)
		self.printFooter(f)
		f.close()

	def filehtml(self, data, path):
		###
		# Files
		files_array = {}
		f = open(path + '/files.html', 'w')
		self.printHeader(f, 'Files')

		f.write('<dl>\n')
		f.write('<dt>Total files</dt><dd>%d</dd>' % data.getTotalFiles())
		f.write('<dt>Total lines</dt><dd>%d</dd>' % data.getTotalLOC())
		try:
			average_file_size = 0
			average_file_size = float(data.getTotalSize()) / data.getTotalFiles()
			f.write('<dt>Average file size</dt><dd>%.2f bytes</dd>' % (average_file_size))
		except ZeroDivisionError:
			pass
		f.write('</dl>\n')

		# Files :: File count by date
		file_count_obj = {'title':'File Count by Date', 'type':'line', 'horizontal':0, 'line1':[]}
		f.write(html_header(2, 'File count by date'))
		# use set to get rid of duplicate/unnecessary entries
		files_by_date = set()
		curfiles = 0
		for stamp in sorted(data.files_by_stamp.keys()):
			if (curfiles != data.files_by_stamp[stamp]):
				file_count_obj['line1'].append([datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), data.files_by_stamp[stamp]])
				files_by_date.add('%s %d' % (datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), data.files_by_stamp[stamp]))
			curfiles = data.files_by_stamp[stamp]

		fg = open(path + '/files_by_date.dat', 'w')
		for line in sorted(list(files_by_date)):
			fg.write('%s\n' % line)
		fg.close()
			
		#f.write('<h2>Average file size by date</h2>')

		# Files :: Extensions
		f.write(html_header(2, 'Extensions'))
		file_extn_obj = {'divid':'file-extn', 'title':'File Extensions', 'type':'table', 'horizontal':0, 'column_headers':[], 'rows':[], "sort_index":1, "sort_order":"desc", "show_count":10}
		self.createTable(f, file_extn_obj['divid'], 'table');
		for column in ("Extension", "Files", "% of files", "lines", "% lines", "lines/file") :
			file_extn_obj['column_headers'].append({'sTitle':column, 'sClass':'center'})
		for ext in sorted(data.extensions.keys()):
			files = data.extensions[ext]['files']
			lines = data.extensions[ext]['lines']
			try:
				loc_percentage = (100.0 * lines) / data.getTotalLOC()
			except ZeroDivisionError:
				loc_percentage = 0
			file_extn_obj['rows'].append([ext, files, math.ceil((100.0 * files)/data.getTotalFiles() * 100) / 100, lines, math.ceil(loc_percentage * 100) / 100, lines/files]);
		files_array['total_files'] = data.getTotalFiles()
		files_array['total_lines'] = data.getTotalLOC()
		files_array['average_file_size'] = average_file_size
		files_array['files_by_date'] = file_count_obj
		files_array['files_extension'] = file_extn_obj
		self.printDataDiv(f, 'files', files_array)
		self.printFooter(f)
		f.close()


	def printHeader(self, f, controller = '', projectname='', title = ''):
		src="assets/css"
		src_files = os.listdir(src)
		cssfiles = ""
		for file_name in src_files:
			full_file_name = os.path.join(src, file_name)
			if (os.path.isfile(full_file_name)):
				if (file_name == "mygitstats.css"):
					cssfiles +="<link rel='stylesheet' href='"+full_file_name+"' type='text/css' />\n\t"
				else :
					cssfiles ="<link rel='stylesheet' href='"+full_file_name+"' type='text/css' />\n\t" + cssfiles

		heading = controller
		if (controller == 'Index'):
			heading = "Git-Awsum-Stats - "+ projectname;
		f.write(
"""<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" ng-app>
<head>
	<title>Git-Awsum-Stats - %s</title>
	%s
	<meta name="generator" content="GitAwesomeStats %s" />
</head>
<body class=background-unFlower>
	<div class='container' ng-controller="%s">
		<h1 class='text-center'>%s</h1>
""" % (self.title, cssfiles, getversion(), controller, heading))
		self.printNav(f)

	def printFooter(self, f, title = ''):
		jsfiles = ""
		#src="assets/js"
		#src_files = os.listdir(src)
		#for file_name in src_files:
			#full_file_name = os.path.join(src, file_name)
			#if (os.path.isfile(full_file_name)):
				#if (file_name == "mygitstats.js"):
					#jsfiles +="<script type='text/javascript' src='"+full_file_name+"' ></script>\n\t"
				#else :
					#jsfiles ="<script type='text/javascript' src='"+full_file_name+"' ></script>\n\t" + jsfiles

		f.write("""
	</div>
	<script src="http://code.jquery.com/jquery-latest.min.js" type="text/javascript"></script>
	<script src="http://code.angularjs.org/1.2.0rc1/angular.min.js"></script>
	<script type='text/javascript' src='assets/js/table-graph-helper.js'></script>
	<script type="text/javascript" src="assets/js/jquery.jqplot.min.js" ></script>
	<script type="text/javascript" src="assets/js/jqplot.barRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.pieRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.donutRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.categoryAxisRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.canvasTextRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.canvasAxisLabelRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.canvasAxisTickRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.pointLabels.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.highlighter.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.cursor.min.js"></script>
	<script type="text/javascript" src="assets/js/jqplot.dateAxisRenderer.min.js"></script>
	<script type="text/javascript" src="assets/js/jquery.dataTables.js"></script>
	<script type="text/javascript" src="assets/js/flatcolors.js"></script>
	<script type="text/javascript" src="assets/js/mygitstats.js"></script>
	%s
</body>
</html>
""" % (jsfiles))

	def printNav(self, f):
		f.write("""
		<ul id="main-nav" class='well inline unstyled main-nav text-center'>
			<li><a href="index.html">General</a></li>
			<li><a href="activity.html">Activity</a></li>
			<li><a href="authors.html">Authors</a></li>
			<li><a href="files.html">Files</a></li>
			<li><a href="lines.html">Lines</a></li>
			<li><a href="tags.html">Tags</a></li>
		</ul>
""")

	def createDiv(self, f, divid, tag):
		f.write("""
		<div class='plot' id=%s></div>
""" % (divid))

	def createTable(self, f, divid, tag):
		f.write("""
		<%s cellpadding=0 cellspacing=0 class='table table-bordered display' id=%s></%s>
""" % (tag, divid, tag))

	def printDataDiv(self, f, div_id, json_array):
		json_data = json.dumps(json_array)
		f.write("""
		<div style='display:none' id=%s data-json='%s'></div>
""" % (div_id, json_data))
		
def usage():
	print """
Usage: gitstats [options] <gitpath..> <outputpath>

Options:
-c key=value     Override configuration value

Default config values:
%s

Please see the manual page for more details.
""" % conf


class GitStats:
	def run(self, args_orig):
		optlist, args = getopt.getopt(args_orig, 'hc:', ["help"])
		for o,v in optlist:
			if o == '-c':
				key, value = v.split('=', 1)
				if key not in conf:
					raise KeyError('no such key "%s" in config' % key)
				if isinstance(conf[key], int):
					conf[key] = int(value)
				elif isinstance(conf[key], dict):
					kk,vv = value.split(',', 1)
					conf[key][kk] = vv
				else:
					conf[key] = value
			elif o in ('-h', '--help'):
				usage()
				sys.exit()

		if len(args) < 2:
			usage()
			sys.exit(0)

		outputpath = os.path.abspath(args[-1])
		rundir = os.getcwd()

		try:
			os.makedirs(outputpath)
			os.makedirs(outputpath + '/assets');
			os.makedirs(outputpath + '/assets/js');
			os.makedirs(outputpath + '/assets/css');
			os.makedirs(outputpath + '/assets/images');
		except OSError:
			pass
		if not os.path.isdir(outputpath):
			print 'FATAL: Output path is not a directory or does not exist'
			sys.exit(1)

		if not getgnuplotversion():
			print 'gnuplot not found'
			sys.exit(1)

		print 'Output path: %s' % outputpath
		cachefile = os.path.join(outputpath, 'gitstats.cache')

		data = GitDataCollector()
		data.loadCache(cachefile)

		for gitpath in args[0:-1]:
			print 'Git path: %s' % gitpath

			os.chdir(gitpath)

			print 'Collecting data...'
			data.collect(gitpath)

		print 'Refining data...'
		data.saveCache(cachefile)
		data.refine()

		os.chdir(rundir)

		print 'Generating report...'
		report = HTMLReportCreator()
		report.create(data, outputpath)

		time_end = time.time()
		exectime_internal = time_end - time_start
		print 'Execution time %.5f secs, %.5f secs (%.2f %%) in external commands)' % (exectime_internal, exectime_external, (100.0 * exectime_external) / exectime_internal)
		if sys.stdin.isatty():
			print 'You may now run:'
			print
			print '   sensible-browser \'%s\'' % os.path.join(outputpath, 'index.html').replace("'", "'\\''")
			print

if __name__=='__main__':
	g = GitStats()
	g.run(sys.argv[1:])

